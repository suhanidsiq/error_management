2025-01-31 06:36:35 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 06:36:35 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:36:35 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:36:35 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:36:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:36:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:36:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:36:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:36:35 [scrapy.extensions.telnet] INFO: Telnet Password: 2ee36790b54ad532
2025-01-31 06:36:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:36:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:36:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:36:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:36:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:36:35 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:36:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:36:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:36:35 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'nonexistenturl.com': <GET http://nonexistenturl.com>
2025-01-31 06:36:35 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:36:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.002902,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 36, 35, 514499, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'memusage/max': 65404928,
 'memusage/startup': 65404928,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 1, 31, 6, 36, 35, 511597, tzinfo=datetime.timezone.utc)}
2025-01-31 06:36:35 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:37:34 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 06:37:34 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:37:34 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:37:34 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:37:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:37:34 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:37:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:37:34 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:37:34 [scrapy.extensions.telnet] INFO: Telnet Password: 6f09d983d396ee68
2025-01-31 06:37:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:37:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:37:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:37:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:37:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:37:34 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:37:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:37:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:37:34 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'nonexistenturl.com': <GET http://nonexistenturl.com>
2025-01-31 06:37:34 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:37:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.00346,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 37, 34, 542848, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'memusage/max': 65015808,
 'memusage/startup': 65015808,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 1, 31, 6, 37, 34, 539388, tzinfo=datetime.timezone.utc)}
2025-01-31 06:37:34 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:39:22 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 06:39:22 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:39:22 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:39:22 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:39:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:39:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:39:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:39:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:39:22 [scrapy.extensions.telnet] INFO: Telnet Password: 461f9b45d4661cd4
2025-01-31 06:39:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:39:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:39:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:39:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:39:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:39:22 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:39:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:39:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:39:22 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'nonexistenturl.com': <GET http://nonexistenturl.com>
2025-01-31 06:39:22 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:39:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.002972,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 39, 22, 369185, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'memusage/max': 65347584,
 'memusage/startup': 65347584,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 1, 31, 6, 39, 22, 366213, tzinfo=datetime.timezone.utc)}
2025-01-31 06:39:22 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:39:49 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:39:49 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:39:49 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:39:49 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:39:49 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:39:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:39:49 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:39:49 [scrapy.extensions.telnet] INFO: Telnet Password: 230abdaad8f094c7
2025-01-31 06:39:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:39:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:39:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:39:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:39:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:39:49 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:39:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:39:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:39:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:39:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1739-515e-ae18-67ba05e24469> from <GET https://nonexistenturl.com/>
2025-01-31 06:39:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1739-515e-ae18-67ba05e24469> (referer: None)
2025-01-31 06:39:52 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1739-515e-ae18-67ba05e24469
2025-01-31 06:39:52 [error] ERROR: Parsing Error :cannot access local variable 'items' where it is not associated with a value
2025-01-31 06:39:52 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:39:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 2.407906,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 39, 52, 251328, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 66265088,
 'memusage/startup': 66265088,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 39, 49, 843422, tzinfo=datetime.timezone.utc)}
2025-01-31 06:39:52 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:41:35 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:41:35 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:41:35 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:41:35 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:41:35 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:41:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:41:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:41:35 [scrapy.extensions.telnet] INFO: Telnet Password: 2287d54837dcb055
2025-01-31 06:41:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:41:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:41:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:41:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:41:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:41:35 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:41:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:41:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:41:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:41:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1741-3576-b3d8-97e9742206b1> from <GET https://nonexistenturl.com/>
2025-01-31 06:41:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1741-3576-b3d8-97e9742206b1> (referer: None)
2025-01-31 06:41:36 [scrapy.core.engine] INFO: Closing spider (Spider Error: Non-200 response)
2025-01-31 06:41:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.720082,
 'finish_reason': 'Spider Error: Non-200 response',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 41, 36, 869778, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 67162112,
 'memusage/startup': 67162112,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 41, 35, 149696, tzinfo=datetime.timezone.utc)}
2025-01-31 06:41:36 [scrapy.core.engine] INFO: Spider closed (Spider Error: Non-200 response)
2025-01-31 06:45:53 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:45:53 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:45:53 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:45:53 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:45:53 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:45:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:45:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:45:53 [scrapy.extensions.telnet] INFO: Telnet Password: 3b57e0097eafe00c
2025-01-31 06:45:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:45:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:45:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:45:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:45:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:45:53 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:45:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:45:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:45:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:45:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1745-533b-a329-9c84ee6f069f> from <GET https://nonexistenturl.com/>
2025-01-31 06:45:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1745-533b-a329-9c84ee6f069f> (referer: None)
2025-01-31 06:45:55 [scrapy.core.engine] INFO: Closing spider (Spider Error: Non-200 response)
2025-01-31 06:45:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.788874,
 'finish_reason': 'Spider Error: Non-200 response',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 45, 55, 30497, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 67121152,
 'memusage/startup': 67121152,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 45, 53, 241623, tzinfo=datetime.timezone.utc)}
2025-01-31 06:45:55 [scrapy.core.engine] INFO: Spider closed (Spider Error: Non-200 response)
2025-01-31 06:47:02 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:47:02 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:47:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:47:02 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:47:02 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:47:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:47:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:47:02 [scrapy.extensions.telnet] INFO: Telnet Password: 18b5cdd865787a36
2025-01-31 06:47:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:47:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:47:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:47:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:47:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:47:02 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:47:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:47:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:47:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:47:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1747-043a-bcc3-2107d617499d> from <GET https://nonexistenturl.com/>
2025-01-31 06:47:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1747-043a-bcc3-2107d617499d> (referer: None)
2025-01-31 06:47:04 [scrapy.core.engine] INFO: Closing spider (Spider Error: Non-200 response)
2025-01-31 06:47:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.738694,
 'finish_reason': 'Spider Error: Non-200 response',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 47, 4, 657314, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 67010560,
 'memusage/startup': 67010560,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 47, 2, 918620, tzinfo=datetime.timezone.utc)}
2025-01-31 06:47:04 [scrapy.core.engine] INFO: Spider closed (Spider Error: Non-200 response)
2025-01-31 06:48:25 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:48:25 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:48:25 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:48:25 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:48:25 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:48:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:48:25 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:48:25 [scrapy.extensions.telnet] INFO: Telnet Password: 8bf571642dc0d35c
2025-01-31 06:48:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:48:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:48:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:48:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:48:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:48:25 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:48:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:48:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:48:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1748-264e-bc39-2003d5ac62f5> from <GET https://nonexistenturl.com/>
2025-01-31 06:48:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1748-264e-bc39-2003d5ac62f5> (referer: None)
2025-01-31 06:48:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ww25.nonexistenturl.com/?subid1=20250131-1748-264e-bc39-2003d5ac62f5> (referer: None)
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/utils/defer.py", line 279, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/referer.py", line 352, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 85, in parse
    self.error_handler.log_error(error_type, error_message, spider.name)
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'error_handler'
2025-01-31 06:48:27 [error] ERROR: Spider error: [Failure instance: Traceback: <class 'AttributeError'>: 'ErrorSpider' object has no attribute 'error_handler'
/usr/lib/python3/dist-packages/twisted/internet/base.py:1090:runUntilCurrent
/usr/lib/python3/dist-packages/twisted/internet/task.py:683:_tick
/usr/lib/python3/dist-packages/twisted/internet/task.py:526:_oneWorkUnit
/usr/lib/python3/dist-packages/scrapy/utils/defer.py:102:<genexpr>
--- <exception caught here> ---
/usr/lib/python3/dist-packages/scrapy/utils/defer.py:279:iter_errback
/usr/lib/python3/dist-packages/scrapy/utils/python.py:350:__next__
/usr/lib/python3/dist-packages/scrapy/utils/python.py:350:__next__
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py:28:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/referer.py:352:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/urllength.py:27:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/depth.py:31:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py:85:parse
]
2025-01-31 06:48:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ErrorSpider.handle_spider_error of <ErrorSpider 'error' at 0x7f2ccc0d7d70>>
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/utils/defer.py", line 279, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/referer.py", line 352, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 85, in parse
    self.error_handler.log_error(error_type, error_message, spider.name)
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'error_handler'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/utils/signal.py", line 46, in send_catch_log
    response = robustApply(
               ^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 116, in handle_spider_error
    self.error_handler.log_error(error_type, error_message, spider.name)
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'error_handler'
2025-01-31 06:48:27 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:48:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.724591,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 48, 27, 60819, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/ERROR': 3,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66949120,
 'memusage/startup': 66949120,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2025, 1, 31, 6, 48, 25, 336228, tzinfo=datetime.timezone.utc)}
2025-01-31 06:48:27 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:49:46 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:49:46 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:49:46 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:49:46 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:49:46 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:49:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:49:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:49:46 [scrapy.extensions.telnet] INFO: Telnet Password: bf9eef453d77f911
2025-01-31 06:49:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:49:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:49:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:49:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:49:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:49:46 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:49:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:49:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:49:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:49:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1749-47e9-8fc3-97e248edb318> from <GET https://nonexistenturl.com/>
2025-01-31 06:49:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1749-47e9-8fc3-97e248edb318> (referer: None)
2025-01-31 06:49:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ww25.nonexistenturl.com/?subid1=20250131-1749-47e9-8fc3-97e248edb318> (referer: None)
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/utils/defer.py", line 279, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/referer.py", line 352, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 85, in parse
    self.error_handler.log_error(error_type, error_message, spider.name)
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'error_handler'
2025-01-31 06:49:48 [error] ERROR: Spider error: [Failure instance: Traceback: <class 'AttributeError'>: 'ErrorSpider' object has no attribute 'error_handler'
/usr/lib/python3/dist-packages/twisted/internet/base.py:1090:runUntilCurrent
/usr/lib/python3/dist-packages/twisted/internet/task.py:683:_tick
/usr/lib/python3/dist-packages/twisted/internet/task.py:526:_oneWorkUnit
/usr/lib/python3/dist-packages/scrapy/utils/defer.py:102:<genexpr>
--- <exception caught here> ---
/usr/lib/python3/dist-packages/scrapy/utils/defer.py:279:iter_errback
/usr/lib/python3/dist-packages/scrapy/utils/python.py:350:__next__
/usr/lib/python3/dist-packages/scrapy/utils/python.py:350:__next__
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py:28:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/referer.py:352:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/urllength.py:27:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/depth.py:31:<genexpr>
/usr/lib/python3/dist-packages/scrapy/core/spidermw.py:106:process_sync
/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py:85:parse
]
2025-01-31 06:49:48 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ErrorSpider.handle_spider_error of <ErrorSpider 'error' at 0x7fad832e7fe0>>
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/utils/defer.py", line 279, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/python.py", line 350, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/referer.py", line 352, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/usr/lib/python3/dist-packages/scrapy/spidermiddlewares/depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/core/spidermw.py", line 106, in process_sync
    for r in iterable:
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 85, in parse
    self.error_handler.log_error(error_type, error_message, spider.name)
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'error_handler'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/utils/signal.py", line 46, in send_catch_log
    response = robustApply(
               ^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 116, in handle_spider_error
    self.error_handler.log_error(error_type, error_message, spider.name)
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'error_handler'
2025-01-31 06:49:48 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:49:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.724404,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 49, 48, 351834, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/ERROR': 3,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66392064,
 'memusage/startup': 66392064,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2025, 1, 31, 6, 49, 46, 627430, tzinfo=datetime.timezone.utc)}
2025-01-31 06:49:48 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:52:41 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:52:41 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:52:41 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-31 06:52:41 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 155, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 169, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/usr/lib/python3/dist-packages/scrapy/spiders/__init__.py", line 59, in from_crawler
    spider = cls(*args, **kwargs)
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 83, in __init__
    self.error_handler = ErrorHandler()  # Now it's correctly instantiated
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/logs/error_handler.py", line 11, in __init__
    self.log_error()
TypeError: ErrorHandler.log_error() missing 2 required positional arguments: 'error_type' and 'error_message'
2025-01-31 06:56:02 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:56:02 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:56:02 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-31 06:56:02 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 155, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 169, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/usr/lib/python3/dist-packages/scrapy/spiders/__init__.py", line 59, in from_crawler
    spider = cls(*args, **kwargs)
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 18, in __init__
    self.error_handler = ErrorHandler()
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/logs/error_handler.py", line 11, in __init__
    self.log_error()
TypeError: ErrorHandler.log_error() missing 2 required positional arguments: 'error_type' and 'error_message'
2025-01-31 06:56:44 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:56:44 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:56:44 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:56:44 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:56:44 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:56:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:56:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:56:44 [scrapy.extensions.telnet] INFO: Telnet Password: a70e562d35dc83b1
2025-01-31 06:56:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:56:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:56:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:56:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:56:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:56:44 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:56:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:56:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:56:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:56:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1756-4552-bd72-44bc603ff0f9> from <GET https://nonexistenturl.com/>
2025-01-31 06:56:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1756-4552-bd72-44bc603ff0f9> (referer: None)
2025-01-31 06:56:45 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1756-4552-bd72-44bc603ff0f9
2025-01-31 06:56:45 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:56:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.759283,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 56, 45, 965729, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67088384,
 'memusage/startup': 67088384,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 56, 44, 206446, tzinfo=datetime.timezone.utc)}
2025-01-31 06:56:45 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:57:30 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:57:30 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:57:30 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:57:30 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:57:30 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:57:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:57:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:57:30 [scrapy.extensions.telnet] INFO: Telnet Password: 8921056185cefe3c
2025-01-31 06:57:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:57:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:57:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:57:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:57:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:57:30 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:57:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:57:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:57:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:57:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1757-3146-ba5b-ab4b17bb68dc> from <GET https://nonexistenturl.com/>
2025-01-31 06:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1757-3146-ba5b-ab4b17bb68dc> (referer: None)
2025-01-31 06:57:32 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1757-3146-ba5b-ab4b17bb68dc
2025-01-31 06:57:32 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:57:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.752101,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 57, 32, 651426, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67133440,
 'memusage/startup': 67133440,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 57, 30, 899325, tzinfo=datetime.timezone.utc)}
2025-01-31 06:57:32 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:57:56 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 06:57:56 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:57:56 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:57:56 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:57:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:57:56 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:57:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:57:56 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:57:56 [scrapy.extensions.telnet] INFO: Telnet Password: 29cf46d9d04e5292
2025-01-31 06:57:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:57:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:57:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:57:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:57:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:57:56 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:57:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:57:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:57:56 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'nonexistenturl.com': <GET http://nonexistenturl.com>
2025-01-31 06:57:56 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:57:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.003277,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 57, 56, 474874, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'memusage/max': 65445888,
 'memusage/startup': 65445888,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 1, 31, 6, 57, 56, 471597, tzinfo=datetime.timezone.utc)}
2025-01-31 06:57:56 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:58:16 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:58:16 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:58:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:58:16 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:58:16 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:58:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:58:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:58:16 [scrapy.extensions.telnet] INFO: Telnet Password: eec404d4754ce475
2025-01-31 06:58:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:58:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:58:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:58:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:58:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:58:16 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:58:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:58:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:58:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:58:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1758-17e8-bc86-906476fee8b9> from <GET https://nonexistenturl.com/>
2025-01-31 06:58:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1758-17e8-bc86-906476fee8b9> (referer: None)
2025-01-31 06:58:18 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1758-17e8-bc86-906476fee8b9
2025-01-31 06:58:18 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:58:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.765057,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 58, 18, 109537, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67178496,
 'memusage/startup': 67178496,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 58, 16, 344480, tzinfo=datetime.timezone.utc)}
2025-01-31 06:58:18 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 06:59:28 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 06:59:28 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 06:59:28 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 06:59:28 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 06:59:28 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 06:59:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 06:59:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 06:59:28 [scrapy.extensions.telnet] INFO: Telnet Password: 098b99312a6e5909
2025-01-31 06:59:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 06:59:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 06:59:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 06:59:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 06:59:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 06:59:28 [scrapy.core.engine] INFO: Spider opened
2025-01-31 06:59:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 06:59:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 06:59:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 06:59:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1759-293c-94ef-2f1f9ddda41e> from <GET https://nonexistenturl.com/>
2025-01-31 06:59:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1759-293c-94ef-2f1f9ddda41e> (referer: None)
2025-01-31 06:59:30 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1759-293c-94ef-2f1f9ddda41e
2025-01-31 06:59:30 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 06:59:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.745486,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 6, 59, 30, 146552, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67223552,
 'memusage/startup': 67223552,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 6, 59, 28, 401066, tzinfo=datetime.timezone.utc)}
2025-01-31 06:59:30 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:00:42 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:00:42 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:00:42 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:00:42 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:00:42 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:00:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:00:42 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:00:42 [scrapy.extensions.telnet] INFO: Telnet Password: 7adcb860d4659228
2025-01-31 07:00:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:00:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:00:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:00:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:00:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:00:42 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:00:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:00:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:00:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:00:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1800-43bc-948a-0c05fe516051> from <GET https://nonexistenturl.com/>
2025-01-31 07:00:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1800-43bc-948a-0c05fe516051> (referer: None)
2025-01-31 07:00:44 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1800-43bc-948a-0c05fe516051
2025-01-31 07:00:44 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:00:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.789493,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 0, 44, 64627, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67174400,
 'memusage/startup': 67174400,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 0, 42, 275134, tzinfo=datetime.timezone.utc)}
2025-01-31 07:00:44 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:01:34 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:01:34 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:01:34 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:01:34 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:01:34 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:01:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:01:34 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:01:34 [scrapy.extensions.telnet] INFO: Telnet Password: dd1051c4f42ca8f5
2025-01-31 07:01:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:01:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:01:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:01:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:01:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:01:34 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:01:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:01:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:01:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:01:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1801-3560-b78d-3ce8a5c5acdb> from <GET https://nonexistenturl.com/>
2025-01-31 07:01:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1801-3560-b78d-3ce8a5c5acdb> (referer: None)
2025-01-31 07:01:36 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1801-3560-b78d-3ce8a5c5acdb
2025-01-31 07:01:36 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:01:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 2.147581,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 1, 36, 720076, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67067904,
 'memusage/startup': 67067904,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 1, 34, 572495, tzinfo=datetime.timezone.utc)}
2025-01-31 07:01:36 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:04:57 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:04:57 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:04:57 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:04:57 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:04:57 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:04:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:04:57 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:04:57 [scrapy.extensions.telnet] INFO: Telnet Password: aa033f02bfc1bd13
2025-01-31 07:04:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:04:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:04:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:04:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:04:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:04:57 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:04:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:04:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:04:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:04:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1804-5811-80e6-a42ccbd65d30> from <GET https://nonexistenturl.com/>
2025-01-31 07:04:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1804-5811-80e6-a42ccbd65d30> (referer: None)
2025-01-31 07:04:59 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1804-5811-80e6-a42ccbd65d30
2025-01-31 07:04:59 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:04:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.769163,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 4, 59, 170391, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67174400,
 'memusage/startup': 67174400,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 4, 57, 401228, tzinfo=datetime.timezone.utc)}
2025-01-31 07:04:59 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:07:11 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:07:11 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:07:11 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:07:11 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:07:11 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:07:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:07:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:07:11 [scrapy.extensions.telnet] INFO: Telnet Password: 182200744617a984
2025-01-31 07:07:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:07:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:07:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:07:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:07:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:07:11 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:07:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:07:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:07:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:07:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1807-1116-b6cc-1d867b85d066> from <GET https://nonexistenturl.com/>
2025-01-31 07:07:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1807-1116-b6cc-1d867b85d066> (referer: None)
2025-01-31 07:07:12 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1807-1116-b6cc-1d867b85d066
2025-01-31 07:07:12 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:07:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.699818,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 7, 12, 936355, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67137536,
 'memusage/startup': 67137536,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 7, 11, 236537, tzinfo=datetime.timezone.utc)}
2025-01-31 07:07:12 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:09:18 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:09:18 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:09:18 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:09:18 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:09:18 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:09:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:09:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:09:18 [scrapy.extensions.telnet] INFO: Telnet Password: f8e4723f4768bd32
2025-01-31 07:09:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:09:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:09:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:09:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:09:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:09:18 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:09:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:09:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:09:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:09:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1809-19a3-9712-a4957f58b575> from <GET https://nonexistenturl.com/>
2025-01-31 07:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1809-19a3-9712-a4957f58b575> (referer: None)
2025-01-31 07:09:20 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1809-19a3-9712-a4957f58b575
2025-01-31 07:09:20 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:09:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.746185,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 9, 20, 409173, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67117056,
 'memusage/startup': 67117056,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 9, 18, 662988, tzinfo=datetime.timezone.utc)}
2025-01-31 07:09:20 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:10:13 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:10:13 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:10:13 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:10:13 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:10:13 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:10:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:10:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:10:13 [scrapy.extensions.telnet] INFO: Telnet Password: 1273002ac2c19f0c
2025-01-31 07:10:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:10:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:10:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:10:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:10:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:10:13 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:10:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:10:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:10:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:10:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1810-14e4-a9aa-b98883379659> from <GET https://nonexistenturl.com/>
2025-01-31 07:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1810-14e4-a9aa-b98883379659> (referer: None)
2025-01-31 07:10:15 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1810-14e4-a9aa-b98883379659
2025-01-31 07:10:15 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:10:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.739427,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 10, 15, 558076, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 67014656,
 'memusage/startup': 67014656,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 10, 13, 818649, tzinfo=datetime.timezone.utc)}
2025-01-31 07:10:15 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:20:55 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:20:55 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:20:55 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:20:55 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:20:55 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:20:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:20:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:20:55 [scrapy.extensions.telnet] INFO: Telnet Password: 7aef62598c5a2065
2025-01-31 07:20:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:20:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:20:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:20:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:20:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:20:55 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:20:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:20:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:20:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:20:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1820-5635-b5dc-74a4ac25acac> from <GET https://nonexistenturl.com/>
2025-01-31 07:20:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1820-5635-b5dc-74a4ac25acac> (referer: None)
2025-01-31 07:20:57 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1820-5635-b5dc-74a4ac25acac
2025-01-31 07:20:57 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_ZrDefUgExJ+VNtnttHsjjBKjz9E2AvvJ'
2025-01-31 07:20:57 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:20:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.728661,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 20, 57, 525407, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 67047424,
 'memusage/startup': 67047424,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 20, 55, 796746, tzinfo=datetime.timezone.utc)}
2025-01-31 07:20:57 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:21:27 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:21:27 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:21:27 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:21:27 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:21:27 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:21:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:21:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:21:27 [scrapy.extensions.telnet] INFO: Telnet Password: 7dcfa58eecb68227
2025-01-31 07:21:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:21:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:21:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:21:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:21:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:21:27 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:21:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:21:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:21:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:21:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1821-2780-b052-e9ab6408c78d> from <GET https://nonexistenturl.com/>
2025-01-31 07:21:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1821-2780-b052-e9ab6408c78d> (referer: None)
2025-01-31 07:21:28 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1821-2780-b052-e9ab6408c78d
2025-01-31 07:21:28 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_SAA6YC+3utlnNbsLX/HsgzpUZkrzKksX'
2025-01-31 07:21:28 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:21:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.710219,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 21, 28, 903712, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 67231744,
 'memusage/startup': 67231744,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 21, 27, 193493, tzinfo=datetime.timezone.utc)}
2025-01-31 07:21:28 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:26:04 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:26:04 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:26:04 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:26:04 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:26:04 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:26:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:26:04 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:26:04 [scrapy.extensions.telnet] INFO: Telnet Password: d2e86d3ffc3e011b
2025-01-31 07:26:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:26:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:26:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:26:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:26:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:26:04 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:26:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:26:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:26:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:26:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1826-055f-a724-80e0003acf49> from <GET https://nonexistenturl.com/>
2025-01-31 07:26:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1826-055f-a724-80e0003acf49> (referer: None)
2025-01-31 07:26:06 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1826-055f-a724-80e0003acf49
2025-01-31 07:26:06 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_gzzY1T6yluW921+P0crSBxm+dBSV396k'
2025-01-31 07:26:06 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:26:06 [scrapy.extensions.feedexport] INFO: Stored xml feed (0 items) in: data.xml
2025-01-31 07:26:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.751636,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 26, 6, 211025, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'memusage/max': 67350528,
 'memusage/startup': 67350528,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 26, 4, 459389, tzinfo=datetime.timezone.utc)}
2025-01-31 07:26:06 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 07:26:32 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 07:26:32 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 07:26:32 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 07:26:32 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 07:26:32 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 07:26:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 07:26:32 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 07:26:32 [scrapy.extensions.telnet] INFO: Telnet Password: dd17035af16ebba1
2025-01-31 07:26:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 07:26:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 07:26:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 07:26:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 07:26:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 07:26:33 [scrapy.core.engine] INFO: Spider opened
2025-01-31 07:26:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 07:26:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 07:26:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 07:26:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-1826-3403-bdf7-ef44ed975032> from <GET https://nonexistenturl.com/>
2025-01-31 07:26:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-1826-3403-bdf7-ef44ed975032> (referer: None)
2025-01-31 07:26:34 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-1826-3403-bdf7-ef44ed975032
2025-01-31 07:26:34 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_LLz+fSv8rxbWceXBCEmRTfU6+NIXeKKZ'
2025-01-31 07:26:34 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 07:26:34 [scrapy.extensions.feedexport] INFO: Stored xml feed (0 items) in: data.xml
2025-01-31 07:26:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.80031,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 7, 26, 34, 900785, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'memusage/max': 67309568,
 'memusage/startup': 67309568,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 7, 26, 33, 100475, tzinfo=datetime.timezone.utc)}
2025-01-31 07:26:34 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:25:25 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:25:25 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:25:25 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:25:25 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:25:25 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:25:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:25:25 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:25:25 [scrapy.extensions.telnet] INFO: Telnet Password: d145c2a96d2e09ab
2025-01-31 09:25:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:25:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:25:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:25:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:25:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:25:25 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:25:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:25:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nonexistenturl.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: nonexistenturl.com.
2025-01-31 09:25:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:25:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2025-452f-ab3d-2a5482bf43e8> from <GET https://nonexistenturl.com/>
2025-01-31 09:25:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2025-452f-ab3d-2a5482bf43e8> (referer: None)
2025-01-31 09:25:46 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2025-452f-ab3d-2a5482bf43e8
2025-01-31 09:25:46 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_uv6H/H4kcRkiDRjBu6blxy1Xuyvwnacy'
2025-01-31 09:25:46 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:25:46 [scrapy.extensions.feedexport] INFO: Stored xml feed (0 items) in: data.xml
2025-01-31 09:25:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 1,
 'downloader/request_bytes': 2229,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 20.303712,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 25, 46, 300117, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 7,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'memusage/max': 67289088,
 'memusage/startup': 67289088,
 'response_received_count': 1,
 'retry/count': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2025, 1, 31, 9, 25, 25, 996405, tzinfo=datetime.timezone.utc)}
2025-01-31 09:25:46 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:26:15 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:26:15 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:26:15 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:26:15 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:26:15 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:26:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:26:15 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:26:15 [scrapy.extensions.telnet] INFO: Telnet Password: 3b0a85c27081200a
2025-01-31 09:26:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:26:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:26:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:26:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:26:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:26:15 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:26:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:26:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:26:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:26:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2026-166e-bb0e-ef98e064591b> from <GET https://nonexistenturl.com/>
2025-01-31 09:26:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2026-166e-bb0e-ef98e064591b> (referer: None)
2025-01-31 09:26:17 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2026-166e-bb0e-ef98e064591b
2025-01-31 09:26:17 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_NfFW3LdPGaBB2jqZMaGbcSkj2g8cRlZQ'
2025-01-31 09:26:17 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:26:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.701143,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 26, 17, 260393, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 67117056,
 'memusage/startup': 67117056,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 26, 15, 559250, tzinfo=datetime.timezone.utc)}
2025-01-31 09:26:17 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:54:32 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:54:32 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:54:32 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:54:32 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:54:32 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:54:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:54:32 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:54:32 [scrapy.extensions.telnet] INFO: Telnet Password: 3860c5bb85c63b54
2025-01-31 09:54:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:54:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:54:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:54:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:54:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:54:32 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:54:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:54:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:54:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:54:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2054-334b-965b-2e35959910ff> from <GET https://nonexistenturl.com/>
2025-01-31 09:54:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2054-334b-965b-2e35959910ff> (referer: None)
2025-01-31 09:54:34 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2054-334b-965b-2e35959910ff
2025-01-31 09:54:34 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_AQ77n2/BIpdvzP3QuJObSWpR6o3fQLbl'
2025-01-31 09:54:34 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:54:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.691571,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 54, 34, 226544, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 67186688,
 'memusage/startup': 67186688,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 54, 32, 534973, tzinfo=datetime.timezone.utc)}
2025-01-31 09:54:34 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:54:53 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:54:53 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:54:53 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:54:53 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:54:53 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:54:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:54:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:54:53 [scrapy.extensions.telnet] INFO: Telnet Password: c33b6e1165782be2
2025-01-31 09:54:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:54:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:54:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:54:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:54:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:54:53 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:54:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:54:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:54:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:54:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2054-5481-9b53-82cc08bcb81a> from <GET https://nonexistenturl.com/>
2025-01-31 09:54:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2054-5481-9b53-82cc08bcb81a> (referer: None)
2025-01-31 09:54:55 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2054-5481-9b53-82cc08bcb81a
2025-01-31 09:54:55 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_U1MisabQokSgI1DEblzTUd4CniiPnQH7'
2025-01-31 09:54:55 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:54:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.700745,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 54, 55, 279316, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 67141632,
 'memusage/startup': 67141632,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 54, 53, 578571, tzinfo=datetime.timezone.utc)}
2025-01-31 09:54:55 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:55:18 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:55:18 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:55:18 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:55:18 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:55:18 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:55:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:55:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:55:18 [scrapy.extensions.telnet] INFO: Telnet Password: 49746fd8d78894b1
2025-01-31 09:55:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:55:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:55:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:55:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:55:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:55:18 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:55:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:55:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:55:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:55:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2055-19b0-8e77-7642f4895f7d> from <GET https://nonexistenturl.com/>
2025-01-31 09:55:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2055-19b0-8e77-7642f4895f7d> (referer: None)
2025-01-31 09:55:20 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2055-19b0-8e77-7642f4895f7d
2025-01-31 09:55:20 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_vq/rBM6XOCHD4OyggIR9uZv6q4UbDXnH'
2025-01-31 09:55:20 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:55:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.717324,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 55, 20, 432055, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 66981888,
 'memusage/startup': 66981888,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 55, 18, 714731, tzinfo=datetime.timezone.utc)}
2025-01-31 09:55:20 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:56:32 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:56:32 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:56:32 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:56:32 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:56:32 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:56:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:56:32 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:56:32 [scrapy.extensions.telnet] INFO: Telnet Password: f9274ffc79a4edfb
2025-01-31 09:56:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:56:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:56:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:56:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:56:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:56:32 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:56:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:56:32 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/spidermiddlewares/offsite.py:74: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://nonexistenturl.com in allowed_domains.
  warnings.warn(message, URLWarning)

2025-01-31 09:56:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:56:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:56:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2056-331a-8e91-f69d73dce942> from <GET https://nonexistenturl.com/>
2025-01-31 09:56:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2056-331a-8e91-f69d73dce942> (referer: None)
2025-01-31 09:56:34 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2056-331a-8e91-f69d73dce942
2025-01-31 09:56:34 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_xoxAdN33FWsSTWiZYSt69uAqHEYbnDyh'
2025-01-31 09:56:34 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:56:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.755484,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 56, 34, 594293, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 2,
 'memusage/max': 67235840,
 'memusage/startup': 67235840,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 56, 32, 838809, tzinfo=datetime.timezone.utc)}
2025-01-31 09:56:34 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:57:24 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:57:24 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:57:24 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:57:24 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:57:24 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:57:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:57:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:57:24 [scrapy.extensions.telnet] INFO: Telnet Password: 9746310d06967644
2025-01-31 09:57:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:57:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:57:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:57:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:57:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:57:24 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:57:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:57:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:57:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:57:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2057-25fb-90a2-d743e77dc52b> from <GET https://nonexistenturl.com/>
2025-01-31 09:57:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2057-25fb-90a2-d743e77dc52b> (referer: None)
2025-01-31 09:57:25 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2057-25fb-90a2-d743e77dc52b
2025-01-31 09:57:25 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_phHttZYmInLkFE7+xbAxoCnxqmnY9iaZ'
2025-01-31 09:57:25 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:57:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.703834,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 57, 25, 855204, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 66363392,
 'memusage/startup': 66363392,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 57, 24, 151370, tzinfo=datetime.timezone.utc)}
2025-01-31 09:57:25 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 09:59:38 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 09:59:38 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 09:59:38 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 09:59:38 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 09:59:38 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 09:59:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 09:59:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 09:59:38 [scrapy.extensions.telnet] INFO: Telnet Password: a597adc12f31bd78
2025-01-31 09:59:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 09:59:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 09:59:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 09:59:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 09:59:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 09:59:38 [scrapy.core.engine] INFO: Spider opened
2025-01-31 09:59:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 09:59:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 09:59:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 09:59:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2059-390d-898a-40fdf613feac> from <GET https://nonexistenturl.com/>
2025-01-31 09:59:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2059-390d-898a-40fdf613feac> (referer: None)
2025-01-31 09:59:40 [error] INFO: Crawling: http://ww25.nonexistenturl.com/?subid1=20250131-2059-390d-898a-40fdf613feac
2025-01-31 09:59:40 [error] INFO: Response body snippet: b'<!doctype html>\n<html data-adblockkey="MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_KhqtPqvhVVyRkDQbrJ0oO+ERB6KOz8Kz'
2025-01-31 09:59:40 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 09:59:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1701,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2366,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 2,
 'elapsed_time_seconds': 1.745708,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 9, 59, 40, 543616, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 66101248,
 'memusage/startup': 66101248,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 9, 59, 38, 797908, tzinfo=datetime.timezone.utc)}
2025-01-31 09:59:40 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:03:14 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:03:14 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:03:14 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:03:14 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:03:14 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:03:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:03:14 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:03:14 [scrapy.extensions.telnet] INFO: Telnet Password: b16ec61182602499
2025-01-31 10:03:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:03:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:03:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:03:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:03:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:03:14 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:03:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:03:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2025-01-31 10:03:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 10:03:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2103-150e-ae58-2f2a99aa0f01> from <GET https://nonexistenturl.com/>
2025-01-31 10:03:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2103-150e-ae58-2f2a99aa0f01> (referer: None)
2025-01-31 10:04:00 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:04:00 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:04:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:04:00 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:04:00 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:04:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:04:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:04:00 [scrapy.extensions.telnet] INFO: Telnet Password: d67eb4472170f394
2025-01-31 10:04:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:04:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:04:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:04:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:04:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:04:00 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:04:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:04:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2025-01-31 10:04:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 10:04:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2104-01a1-966d-852a3d6b4635> from <GET https://nonexistenturl.com/>
2025-01-31 10:04:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2104-01a1-966d-852a3d6b4635> (referer: None)
2025-01-31 10:05:12 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:05:12 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:05:12 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:05:12 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:05:12 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:05:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:05:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:05:12 [scrapy.extensions.telnet] INFO: Telnet Password: d5d1d19a0771d6a5
2025-01-31 10:05:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:05:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:05:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:05:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:05:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:05:13 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:05:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:05:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2025-01-31 10:05:13 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 181, in _next_request
    request = next(self.slot.start_requests)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 24, in start_requests
    yield scrapy.Request(self.start_urls, callback=self.parse)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/lib/python3/dist-packages/scrapy/http/request/__init__.py", line 133, in _set_url
    raise TypeError(f"Request url must be str, got {type(url).__name__}")
TypeError: Request url must be str, got list
2025-01-31 10:05:13 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:05:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.011522,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 5, 13, 15911, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66441216,
 'memusage/startup': 66441216,
 'start_time': datetime.datetime(2025, 1, 31, 10, 5, 13, 4389, tzinfo=datetime.timezone.utc)}
2025-01-31 10:05:13 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:05:37 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:05:37 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:05:37 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:05:37 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:05:37 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:05:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:05:37 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:05:37 [scrapy.extensions.telnet] INFO: Telnet Password: 08b45990d3377928
2025-01-31 10:05:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:05:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:05:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:05:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:05:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:05:37 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:05:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:05:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2025-01-31 10:05:37 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 181, in _next_request
    request = next(self.slot.start_requests)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 24, in start_requests
    yield scrapy.Request(self.start_urls, callback=self.parse)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/lib/python3/dist-packages/scrapy/http/request/__init__.py", line 133, in _set_url
    raise TypeError(f"Request url must be str, got {type(url).__name__}")
TypeError: Request url must be str, got list
2025-01-31 10:05:37 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:05:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.006293,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 5, 37, 625097, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66314240,
 'memusage/startup': 66314240,
 'start_time': datetime.datetime(2025, 1, 31, 10, 5, 37, 618804, tzinfo=datetime.timezone.utc)}
2025-01-31 10:05:37 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:06:18 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:06:18 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:06:18 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:06:18 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:06:18 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:06:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:06:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:06:18 [scrapy.extensions.telnet] INFO: Telnet Password: f1ec752d273152c7
2025-01-31 10:06:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:06:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:06:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:06:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:06:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:06:18 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:06:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:06:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2025-01-31 10:06:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sssssgfbtf.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: sssssgfbtf.com.
2025-01-31 10:06:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sssssgfbtf.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: sssssgfbtf.com.
2025-01-31 10:06:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://sssssgfbtf.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: sssssgfbtf.com.
2025-01-31 10:06:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://sssssgfbtf.com>
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1999, in _inlineCallbacks
    result = context.run(
  File "/usr/lib/python3/dist-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/lib/python3/dist-packages/twisted/internet/endpoints.py", line 1025, in startConnectionAttempts
    raise error.DNSLookupError(
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: sssssgfbtf.com.
2025-01-31 10:06:18 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:06:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1572,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 0.410417,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 6, 18, 732355, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66310144,
 'memusage/startup': 66310144,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 10, 6, 18, 321938, tzinfo=datetime.timezone.utc)}
2025-01-31 10:06:18 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:06:44 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:06:44 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:06:44 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:06:44 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:06:44 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:06:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:06:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:06:44 [scrapy.extensions.telnet] INFO: Telnet Password: b4cba07b62cd4801
2025-01-31 10:06:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:06:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:06:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:06:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:06:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:06:44 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:06:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:06:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2025-01-31 10:06:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://nonexistenturl.com/> from <GET http://nonexistenturl.com>
2025-01-31 10:06:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww25.nonexistenturl.com/?subid1=20250131-2106-45b8-a024-c07c0e6345d1> from <GET https://nonexistenturl.com/>
2025-01-31 10:06:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww25.nonexistenturl.com/?subid1=20250131-2106-45b8-a024-c07c0e6345d1> (referer: None)
2025-01-31 10:09:04 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:09:04 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:09:04 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:09:04 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:09:04 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:09:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:09:04 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:09:04 [scrapy.extensions.telnet] INFO: Telnet Password: 9828b5ba69128597
2025-01-31 10:09:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:09:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:09:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:09:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:09:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:09:04 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:09:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:09:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034
2025-01-31 10:09:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.amazon.com/ref=as_li_ss_tl?_encoding=UTF8&camp=1789&creative=390957&linkCode=ur2&tag=amznipops-20&linkId=VETEOIMPO7O4WRWZ> from <GET http://amazonnn.com>
2025-01-31 10:09:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.amazon.com/ref=as_li_ss_tl?_encoding=UTF8&camp=1789&creative=390957&linkCode=ur2&tag=amznipops-20&linkId=VETEOIMPO7O4WRWZ> from <GET http://www.amazon.com/ref=as_li_ss_tl?_encoding=UTF8&camp=1789&creative=390957&linkCode=ur2&tag=amznipops-20&linkId=VETEOIMPO7O4WRWZ>
2025-01-31 10:09:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/ref=as_li_ss_tl?_encoding=UTF8&camp=1789&creative=390957&linkCode=ur2&tag=amznipops-20&linkId=VETEOIMPO7O4WRWZ> (referer: None)
2025-01-31 10:09:36 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:09:36 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:09:36 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:09:36 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:09:36 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:09:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:09:36 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:09:36 [scrapy.extensions.telnet] INFO: Telnet Password: a8078eb7b9ad900b
2025-01-31 10:09:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:09:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:09:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:09:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:09:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:09:36 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:09:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:09:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:09:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:09:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:09:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://amazonnnsuhani.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:09:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://amazonnnsuhani.com>
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1999, in _inlineCallbacks
    result = context.run(
  File "/usr/lib/python3/dist-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/lib/python3/dist-packages/twisted/internet/endpoints.py", line 1025, in startConnectionAttempts
    raise error.DNSLookupError(
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:09:36 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:09:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1584,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 0.378172,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 9, 36, 505235, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66441216,
 'memusage/startup': 66441216,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 10, 9, 36, 127063, tzinfo=datetime.timezone.utc)}
2025-01-31 10:09:36 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:12:39 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:12:39 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:12:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:12:39 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:12:39 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:12:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:12:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:12:39 [scrapy.extensions.telnet] INFO: Telnet Password: 9cd23c8390778aa1
2025-01-31 10:12:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:12:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:12:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:12:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:12:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:12:40 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:12:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:12:40 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 181, in _next_request
    request = next(self.slot.start_requests)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 24, in start_requests
    yield scrapy.Request('http://amazonnnsuhani.com', callback=self.parse,errback=self.handle_error)
                                                                                  ^^^^^^^^^^^^^^^^^
AttributeError: 'ErrorSpider' object has no attribute 'handle_error'
2025-01-31 10:12:40 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:12:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.007243,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 12, 40, 96886, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66322432,
 'memusage/startup': 66322432,
 'start_time': datetime.datetime(2025, 1, 31, 10, 12, 40, 89643, tzinfo=datetime.timezone.utc)}
2025-01-31 10:12:40 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:13:36 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:13:36 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:13:36 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:13:36 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:13:36 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:13:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:13:36 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:13:36 [scrapy.extensions.telnet] INFO: Telnet Password: 73af130f647cc406
2025-01-31 10:13:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:13:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:13:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:13:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:13:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:13:36 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:13:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:13:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:13:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:13:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:13:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://amazonnnsuhani.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:13:36 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'twisted.internet.error.DNSLookupError'>: DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
/usr/lib/python3/dist-packages/twisted/internet/defer.py:916:errback
/usr/lib/python3/dist-packages/twisted/internet/defer.py:984:_startRunCallbacks
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1078:_runCallbacks
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1949:_gotResultInlineCallbacks
--- <exception caught here> ---
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1999:_inlineCallbacks
/usr/lib/python3/dist-packages/twisted/python/failure.py:519:throwExceptionIntoGenerator
/usr/lib/python3/dist-packages/scrapy/core/downloader/middleware.py:54:process_request
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1078:_runCallbacks
/usr/lib/python3/dist-packages/twisted/internet/endpoints.py:1025:startConnectionAttempts
]
2025-01-31 10:13:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://amazonnnsuhani.com>
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1999, in _inlineCallbacks
    result = context.run(
  File "/usr/lib/python3/dist-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/lib/python3/dist-packages/twisted/internet/endpoints.py", line 1025, in startConnectionAttempts
    raise error.DNSLookupError(
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:13:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://amazonnnsuhani.com> (referer: None)
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Mediaamp-learning/Scrapy_Errors/errors/errors/spiders/error.py", line 93, in handle_error
    response = failure.value.response if failure.check(scrapy.exceptions.HttpError) else None
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'scrapy.exceptions' has no attribute 'HttpError'
2025-01-31 10:13:36 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:13:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1584,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 0.387774,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 13, 36, 642743, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66322432,
 'memusage/startup': 66322432,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 13, 36, 254969, tzinfo=datetime.timezone.utc)}
2025-01-31 10:13:36 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:15:19 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:15:19 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:15:19 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:15:19 [py.warnings] WARNING: /usr/lib/python3/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2025-01-31 10:15:19 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:15:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:15:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:15:19 [scrapy.extensions.telnet] INFO: Telnet Password: b6777dfa55ce2e2b
2025-01-31 10:15:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:15:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:15:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:15:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:15:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:15:19 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:15:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:15:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://amazonnnsuhani.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:15:19 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'twisted.internet.error.DNSLookupError'>: DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
/usr/lib/python3/dist-packages/twisted/internet/defer.py:916:errback
/usr/lib/python3/dist-packages/twisted/internet/defer.py:984:_startRunCallbacks
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1078:_runCallbacks
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1949:_gotResultInlineCallbacks
--- <exception caught here> ---
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1999:_inlineCallbacks
/usr/lib/python3/dist-packages/twisted/python/failure.py:519:throwExceptionIntoGenerator
/usr/lib/python3/dist-packages/scrapy/core/downloader/middleware.py:54:process_request
/usr/lib/python3/dist-packages/twisted/internet/defer.py:1078:_runCallbacks
/usr/lib/python3/dist-packages/twisted/internet/endpoints.py:1025:startConnectionAttempts
]
2025-01-31 10:15:19 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:15:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1584,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 0.41376,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 15, 19, 803523, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 66314240,
 'memusage/startup': 66314240,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 10, 15, 19, 389763, tzinfo=datetime.timezone.utc)}
2025-01-31 10:15:19 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:15:56 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: errors)
2025-01-31 10:15:56 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:16:31 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:16:31 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:16:31 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:16:31 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:16:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:16:31 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:16:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:16:31 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:16:31 [scrapy.extensions.telnet] INFO: Telnet Password: 7e20ceeda3244f27
2025-01-31 10:16:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:16:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:16:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:16:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:16:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:16:31 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:16:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:16:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:16:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:16:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://amazonnnsuhani.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:16:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://amazonnnsuhani.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
2025-01-31 10:16:31 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'twisted.internet.error.DNSLookupError'>: DNS lookup failed: no results for hostname lookup: amazonnnsuhani.com.
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/twisted/internet/defer.py:2013:_inlineCallbacks
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/twisted/python/failure.py:467:throwExceptionIntoGenerator
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py:68:process_request
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/twisted/internet/defer.py:1088:_runCallbacks
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/twisted/internet/endpoints.py:1061:startConnectionAttempts
]
2025-01-31 10:16:31 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:16:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1584,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 0.428192,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 16, 31, 878003, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 7,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'memusage/max': 64753664,
 'memusage/startup': 64753664,
 'responses_per_minute': None,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 10, 16, 31, 449811, tzinfo=datetime.timezone.utc)}
2025-01-31 10:16:31 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:18:46 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:18:46 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:18:46 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:18:46 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:18:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:18:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:18:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:18:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:18:46 [scrapy.extensions.telnet] INFO: Telnet Password: 0cb997f5c40a8060
2025-01-31 10:18:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:18:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:18:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:18:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:18:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:18:46 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:18:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:18:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:18:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://amazonn.com:443/> from <GET http://amazonn.com>
2025-01-31 10:18:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.amazon.com:443/> from <GET https://amazonn.com:443/>
2025-01-31 10:18:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com:443/> (referer: None)
2025-01-31 10:18:48 [error] INFO: Crawling: https://www.amazon.com:443/
2025-01-31 10:18:48 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:18:48 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:18:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1566,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 141507,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 2,
 'elapsed_time_seconds': 2.388268,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 18, 48, 821822, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 642027,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 8,
 'log_count/INFO': 12,
 'memusage/max': 65695744,
 'memusage/startup': 65695744,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 31, 10, 18, 46, 433554, tzinfo=datetime.timezone.utc)}
2025-01-31 10:18:48 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:19:53 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:19:53 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:19:53 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:19:53 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:19:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:19:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:19:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:19:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:19:53 [scrapy.extensions.telnet] INFO: Telnet Password: e5cb19dc7acb2754
2025-01-31 10:19:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:19:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:19:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:19:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:19:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:19:53 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:19:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:19:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:19:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/b?node=14253971> (referer: None)
2025-01-31 10:19:55 [error] INFO: Crawling: https://www.amazon.com/b?node=14253971
2025-01-31 10:19:55 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:19:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=2&xpid=oFB3bGBvJxJ0z&c=ts&qid=1738318794&ts_id=14253971&ref=sr_pg_1> (referer: https://www.amazon.com/b?node=14253971)
2025-01-31 10:19:57 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=2&xpid=oFB3bGBvJxJ0z&c=ts&qid=1738318794&ts_id=14253971&ref=sr_pg_1
2025-01-31 10:19:57 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:19:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=3&c=ts&qid=1738318796&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_2> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=2&xpid=oFB3bGBvJxJ0z&c=ts&qid=1738318794&ts_id=14253971&ref=sr_pg_1)
2025-01-31 10:19:59 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=3&c=ts&qid=1738318796&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_2
2025-01-31 10:19:59 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=4&c=ts&qid=1738318798&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_3> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=3&c=ts&qid=1738318796&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_2)
2025-01-31 10:20:01 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=4&c=ts&qid=1738318798&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_3
2025-01-31 10:20:01 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=5&c=ts&qid=1738318799&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_4> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=4&c=ts&qid=1738318798&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_3)
2025-01-31 10:20:02 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=5&c=ts&qid=1738318799&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_4
2025-01-31 10:20:02 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=6&c=ts&qid=1738318801&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_5> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=5&c=ts&qid=1738318799&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_4)
2025-01-31 10:20:04 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=6&c=ts&qid=1738318801&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_5
2025-01-31 10:20:04 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=7&c=ts&qid=1738318802&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_6> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=6&c=ts&qid=1738318801&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_5)
2025-01-31 10:20:05 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=7&c=ts&qid=1738318802&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_6
2025-01-31 10:20:05 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=8&c=ts&qid=1738318804&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_7> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=7&c=ts&qid=1738318802&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_6)
2025-01-31 10:20:06 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=8&c=ts&qid=1738318804&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_7
2025-01-31 10:20:06 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=9&c=ts&qid=1738318805&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_8> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=8&c=ts&qid=1738318804&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_7)
2025-01-31 10:20:07 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=9&c=ts&qid=1738318805&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_8
2025-01-31 10:20:07 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=10&c=ts&qid=1738318806&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_9> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=9&c=ts&qid=1738318805&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_8)
2025-01-31 10:20:09 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=10&c=ts&qid=1738318806&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_9
2025-01-31 10:20:09 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=11&c=ts&qid=1738318808&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_10> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=10&c=ts&qid=1738318806&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_9)
2025-01-31 10:20:10 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=11&c=ts&qid=1738318808&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_10
2025-01-31 10:20:11 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=12&c=ts&qid=1738318809&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_11> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=11&c=ts&qid=1738318808&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_10)
2025-01-31 10:20:12 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=12&c=ts&qid=1738318809&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_11
2025-01-31 10:20:12 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=13&c=ts&qid=1738318811&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_12> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=12&c=ts&qid=1738318809&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_11)
2025-01-31 10:20:13 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=13&c=ts&qid=1738318811&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_12
2025-01-31 10:20:13 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=14&c=ts&qid=1738318812&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_13> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=13&c=ts&qid=1738318811&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_12)
2025-01-31 10:20:14 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=14&c=ts&qid=1738318812&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_13
2025-01-31 10:20:14 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=15&c=ts&qid=1738318813&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_14> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=14&c=ts&qid=1738318812&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_13)
2025-01-31 10:20:15 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=15&c=ts&qid=1738318813&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_14
2025-01-31 10:20:15 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=16&c=ts&qid=1738318814&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_15> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=15&c=ts&qid=1738318813&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_14)
2025-01-31 10:20:17 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=16&c=ts&qid=1738318814&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_15
2025-01-31 10:20:17 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=17&c=ts&qid=1738318815&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_16> (referer: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=16&c=ts&qid=1738318814&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_15)
2025-01-31 10:20:18 [error] INFO: Crawling: https://www.amazon.com/s?k=Mop+Handles&i=hpc&rh=n%3A14253971&page=17&c=ts&qid=1738318815&ts_id=14253971&xpid=oFB3bGBvJxJ0z&ref=sr_pg_16
2025-01-31 10:20:18 [error] INFO: Response body snippet: b'<!doctype html><html lang="en-us" class="a-no-js" data-19ax5a9jf="dingo"><!-- sp:feature:head-start -->\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset="utf-8"/>\n<!-- sp:e'
2025-01-31 10:20:18 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:20:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 20185,
 'downloader/request_count': 17,
 'downloader/request_method_count/GET': 17,
 'downloader/response_bytes': 3105096,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'elapsed_time_seconds': 24.723198,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 20, 18, 419351, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 17133604,
 'httpcompression/response_count': 17,
 'items_per_minute': None,
 'log_count/DEBUG': 22,
 'log_count/INFO': 44,
 'memusage/max': 64593920,
 'memusage/startup': 64593920,
 'request_depth_max': 16,
 'response_received_count': 17,
 'responses_per_minute': None,
 'scheduler/dequeued': 17,
 'scheduler/dequeued/memory': 17,
 'scheduler/enqueued': 17,
 'scheduler/enqueued/memory': 17,
 'start_time': datetime.datetime(2025, 1, 31, 10, 19, 53, 696153, tzinfo=datetime.timezone.utc)}
2025-01-31 10:20:18 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:31:12 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:31:12 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:31:12 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:31:12 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:31:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:31:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:31:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:31:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:31:12 [scrapy.extensions.telnet] INFO: Telnet Password: 37732093c24d9b73
2025-01-31 10:31:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:31:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:31:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:31:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:31:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:31:12 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:31:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:31:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:31:13 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://httpbin.org/status/404> (referer: None)
2025-01-31 10:31:13 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:31:13 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:31:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 219,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.012057,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 31, 13, 447763, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64602112,
 'memusage/startup': 64602112,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 31, 12, 435706, tzinfo=datetime.timezone.utc)}
2025-01-31 10:31:13 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:32:33 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:32:33 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:32:33 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:32:33 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:32:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:32:33 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:32:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:32:33 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:32:33 [scrapy.extensions.telnet] INFO: Telnet Password: 0a09bc13aa2b552f
2025-01-31 10:32:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:32:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:32:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:32:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:32:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:32:33 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:32:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:32:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:32:35 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:32:35 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:32:35 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:32:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 1.154149,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 32, 35, 130188, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64577536,
 'memusage/startup': 64577536,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 32, 33, 976039, tzinfo=datetime.timezone.utc)}
2025-01-31 10:32:35 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:33:51 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:33:51 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:33:51 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:33:51 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:33:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:33:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:33:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:33:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:33:51 [scrapy.extensions.telnet] INFO: Telnet Password: 05c351c301ac8589
2025-01-31 10:33:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:33:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:33:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:33:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:33:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:33:51 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:33:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:33:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:33:52 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:33:52 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:33:52 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:33:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 1.047848,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 33, 52, 703846, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65495040,
 'memusage/startup': 65495040,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 33, 51, 655998, tzinfo=datetime.timezone.utc)}
2025-01-31 10:33:52 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:34:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:34:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:34:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:34:09 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:34:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:34:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:34:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:34:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:34:09 [scrapy.extensions.telnet] INFO: Telnet Password: 1e7020c0266578b5
2025-01-31 10:34:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:34:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:34:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:34:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:34:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:34:09 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:34:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:34:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:34:10 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:34:10 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:34:10 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:34:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 1.013161,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 34, 10, 328453, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64692224,
 'memusage/startup': 64692224,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 34, 9, 315292, tzinfo=datetime.timezone.utc)}
2025-01-31 10:34:10 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:34:38 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:34:38 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:34:38 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:34:38 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:34:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:34:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:34:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:34:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:34:38 [scrapy.extensions.telnet] INFO: Telnet Password: d0b4bda3b8859cca
2025-01-31 10:34:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:34:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:34:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:34:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:34:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:34:38 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:34:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:34:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:34:39 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:34:39 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:34:39 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:34:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 0.993296,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 34, 39, 750025, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65699840,
 'memusage/startup': 65699840,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 34, 38, 756729, tzinfo=datetime.timezone.utc)}
2025-01-31 10:34:39 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:35:10 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:35:10 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:35:10 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:35:10 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:35:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:35:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:35:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:35:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:35:10 [scrapy.extensions.telnet] INFO: Telnet Password: 3f099f0b0db7a76f
2025-01-31 10:35:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:35:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:35:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:35:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:35:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:35:10 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:35:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:35:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:35:11 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:35:11 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:35:11 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:35:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 0.980731,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 35, 11, 124101, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65523712,
 'memusage/startup': 65523712,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 35, 10, 143370, tzinfo=datetime.timezone.utc)}
2025-01-31 10:35:11 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:39:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:39:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:39:21 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:39:21 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:39:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:39:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:39:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:39:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:39:21 [scrapy.extensions.telnet] INFO: Telnet Password: bdd436e1767c1880
2025-01-31 10:39:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:39:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:39:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:39:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:39:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:39:21 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:39:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:39:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:39:22 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:39:22 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:39:22 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:39:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 0.987002,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 39, 22, 199138, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64499712,
 'memusage/startup': 64499712,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 39, 21, 212136, tzinfo=datetime.timezone.utc)}
2025-01-31 10:39:22 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:40:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:40:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:40:21 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:40:21 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:40:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:40:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:40:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:40:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:40:21 [scrapy.extensions.telnet] INFO: Telnet Password: 63df682663a4bb39
2025-01-31 10:40:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:40:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:40:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:40:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:40:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:40:21 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:40:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:40:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:40:22 [scrapy.core.engine] DEBUG: Crawled (300) <GET https://httpbin.org/status/300> (referer: None)
2025-01-31 10:40:22 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:40:22 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:40:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 226,
 'downloader/response_count': 1,
 'downloader/response_status_count/300': 1,
 'elapsed_time_seconds': 0.986749,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 40, 22, 278119, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64614400,
 'memusage/startup': 64614400,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 40, 21, 291370, tzinfo=datetime.timezone.utc)}
2025-01-31 10:40:22 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:40:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:40:39 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:40:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:40:39 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:40:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:40:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:40:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:40:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:40:39 [scrapy.extensions.telnet] INFO: Telnet Password: 739befb0ebfa4dfc
2025-01-31 10:40:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:40:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:40:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:40:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:40:39 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:40:39 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:40:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:40:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:40:40 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:40:40 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:40:40 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:40:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 0.988481,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 40, 40, 804136, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65372160,
 'memusage/startup': 65372160,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 40, 39, 815655, tzinfo=datetime.timezone.utc)}
2025-01-31 10:40:40 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:41:38 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:41:38 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:41:38 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:41:38 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:41:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:41:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:41:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:41:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:41:38 [scrapy.extensions.telnet] INFO: Telnet Password: 2354437344317e5f
2025-01-31 10:41:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:41:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:41:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:41:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:41:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:41:38 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:41:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:41:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:41:39 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:41:39 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:41:39 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:41:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 1.029187,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 41, 39, 483074, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65716224,
 'memusage/startup': 65716224,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 41, 38, 453887, tzinfo=datetime.timezone.utc)}
2025-01-31 10:41:39 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:42:43 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:42:43 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:42:43 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:42:43 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:42:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:42:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:42:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:42:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:42:43 [scrapy.extensions.telnet] INFO: Telnet Password: 6990ad4131b1fd73
2025-01-31 10:42:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:42:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:42:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:42:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:42:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:42:43 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:42:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:42:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:42:44 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:42:44 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:42:44 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:42:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 1.02397,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 42, 44, 583370, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64532480,
 'memusage/startup': 64532480,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 42, 43, 559400, tzinfo=datetime.timezone.utc)}
2025-01-31 10:42:44 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:43:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:43:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:43:21 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:43:21 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:43:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:43:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:43:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:43:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:43:21 [scrapy.extensions.telnet] INFO: Telnet Password: 3414cbcc6d505601
2025-01-31 10:43:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:43:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:43:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:43:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:43:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:43:21 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:43:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:43:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:43:22 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:43:22 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:43:22 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:43:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 1.090815,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 43, 22, 705688, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64434176,
 'memusage/startup': 64434176,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 43, 21, 614873, tzinfo=datetime.timezone.utc)}
2025-01-31 10:43:22 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:44:01 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:44:01 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:44:01 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:44:01 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:44:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:01 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:01 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:01 [scrapy.extensions.telnet] INFO: Telnet Password: 1bee1b9491cd9f8c
2025-01-31 10:44:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:44:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:44:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:44:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:44:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:44:01 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:44:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:44:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:44:02 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:44:02 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:44:02 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:44:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 1.065833,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 44, 2, 499354, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65404928,
 'memusage/startup': 65404928,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 44, 1, 433521, tzinfo=datetime.timezone.utc)}
2025-01-31 10:44:02 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:44:28 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:44:28 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:44:28 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:44:28 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:44:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:28 [scrapy.extensions.telnet] INFO: Telnet Password: c4d2516446928498
2025-01-31 10:44:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:44:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:44:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:44:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:44:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:44:29 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:44:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:44:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:44:29 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:44:30 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:44:30 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:44:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 0.984082,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 44, 30, 32160, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64282624,
 'memusage/startup': 64282624,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 44, 29, 48078, tzinfo=datetime.timezone.utc)}
2025-01-31 10:44:30 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:44:42 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:44:42 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:44:42 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:44:42 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:44:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:42 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:42 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:42 [scrapy.extensions.telnet] INFO: Telnet Password: e2a0e0fd8fbe26da
2025-01-31 10:44:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:44:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:44:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:44:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:44:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:44:42 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:44:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:44:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:44:43 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:44:43 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:44:43 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:44:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 0.978919,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 44, 43, 628156, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65699840,
 'memusage/startup': 65699840,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 44, 42, 649237, tzinfo=datetime.timezone.utc)}
2025-01-31 10:44:43 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:44:44 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:44:44 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:44:44 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:44:44 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:44:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:44:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:44:44 [scrapy.extensions.telnet] INFO: Telnet Password: d2916833855774a8
2025-01-31 10:44:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:44:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:44:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:44:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:44:45 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:44:45 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:44:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:44:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:44:45 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://httpbin.org/status/400> (referer: None)
2025-01-31 10:44:45 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:44:45 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:44:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 221,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 0.972033,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 44, 45, 977313, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 64675840,
 'memusage/startup': 64675840,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 44, 45, 5280, tzinfo=datetime.timezone.utc)}
2025-01-31 10:44:45 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:47:24 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:47:24 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:47:24 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:47:24 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:47:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:47:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:47:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:47:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:47:24 [scrapy.extensions.telnet] INFO: Telnet Password: 983666bba6f5e93e
2025-01-31 10:47:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:47:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:47:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:47:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:47:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:47:24 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:47:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:47:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:47:25 [scrapy.core.engine] DEBUG: Crawled (501) <GET https://httpbin.org/status/501> (referer: None)
2025-01-31 10:47:25 [error] ERROR: Request failed: [Failure instance: Traceback: <class 'scrapy.spidermiddlewares.httperror.HttpError'>: Ignoring non-200 response
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/core/spidermw.py:83:_process_spider_input
/home/spareek/.local/share/virtualenvs/Scrapy_Errors-FJKwbz8e/lib/python3.12/site-packages/scrapy/spidermiddlewares/httperror.py:64:process_spider_input
]
2025-01-31 10:47:25 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:47:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 225,
 'downloader/response_count': 1,
 'downloader/response_status_count/501': 1,
 'elapsed_time_seconds': 0.961633,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 47, 25, 133276, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65335296,
 'memusage/startup': 65335296,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 47, 24, 171643, tzinfo=datetime.timezone.utc)}
2025-01-31 10:47:25 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-31 10:47:40 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: errors)
2025-01-31 10:47:40 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-01-31 10:47:40 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-31 10:47:40 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-31 10:47:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:47:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:47:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-31 10:47:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-31 10:47:40 [scrapy.extensions.telnet] INFO: Telnet Password: 99452d0937baa72c
2025-01-31 10:47:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-31 10:47:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'errors',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/scrapy_log.json',
 'NEWSPIDER_MODULE': 'errors.spiders',
 'SPIDER_MODULES': ['errors.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-31 10:47:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-31 10:47:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-31 10:47:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-31 10:47:40 [scrapy.core.engine] INFO: Spider opened
2025-01-31 10:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-31 10:47:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035
2025-01-31 10:47:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://httpbin.org/status/200> (referer: None)
2025-01-31 10:47:41 [error] INFO: Crawling: https://httpbin.org/status/200
2025-01-31 10:47:41 [error] INFO: Response body snippet: b''
2025-01-31 10:47:41 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-31 10:47:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 212,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.192751,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 31, 10, 47, 41, 590773, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'memusage/max': 65728512,
 'memusage/startup': 65728512,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 31, 10, 47, 40, 398022, tzinfo=datetime.timezone.utc)}
2025-01-31 10:47:41 [scrapy.core.engine] INFO: Spider closed (finished)
